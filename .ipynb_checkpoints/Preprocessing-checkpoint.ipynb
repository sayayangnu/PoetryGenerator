{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function slices the unwanted text (introduction, etc.) at the beginning of the txt file \n",
    "# It takes a string 'my_str', and delete everything before the specified 'sub' \n",
    "def slicer_front(my_str,sub):\n",
    "  index=my_str.find(sub)\n",
    "  if index !=-1 :\n",
    "        return my_str[index:] \n",
    "  else :\n",
    "        raise Exception('Sub string not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function slices the unwanted text (introduction, etc.) at the end of the txt file \n",
    "def slicer_back(my_str,sub):\n",
    "  index=my_str.find(sub)\n",
    "  if index !=-1 :\n",
    "        return my_str[:index] \n",
    "  else :\n",
    "        raise Exception('Sub string not found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(target_url):\n",
    "    r = requests.get(target_url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in from local file: poetry collection \"Collected Poems by Dylan Thomas\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "with open('DylanThomas.txt',\"r\") as f:\n",
    "    f= re.sub(r'\\n\\n\\n\\n\\n.+\\n\\n\\n','\\n', f.read()) ### Remove titles of poems \n",
    "    lines = f.split('\\n') ### Split into lines \n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            corpus.append(line)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in from website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP = get_soup('https://raw.githubusercontent.com/tfavory/pmlg-poem-generator/master/model_training/corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in CP.get_text().split('\\n'):\n",
    "    if line.strip():\n",
    "        corpus.append(line)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38251"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from the website: https://raw.githubusercontent.com/tfavory/pmlg-poem-generator/master/model_training/corpus.txt\n",
    "\n",
    "Poetry Collection: Songs of Innocence and Songs of Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SE = get_soup('http://www.gutenberg.org/files/1934/1934-0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean preface, conclusion and titles\n",
    "SE_txt = slicer_back(slicer_front(SE.get_text(),'How sweet is the shepherd'),'***END OF THE PROJECT GUTENBERG') # Delete the preface and conclusion\n",
    "SE_txt_c = re.sub('\\r\\n\\r\\n\\r\\n\\r\\n.+\\r\\n\\r\\n\\r\\n','\\r\\n',SE_txt) # Clean the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append sentances\n",
    "for line in SE_txt_c.split('\\r\\n'):\n",
    "    if line.strip():\n",
    "        corpus.append(line)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39141"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read from website: http://www.gutenberg.org/cache/epub/8789/pg8789.txt\n",
    "\n",
    "Divine Comedy by Dante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE = get_soup('http://www.gutenberg.org/cache/epub/8789/pg8789.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean preface, conclusion and titles\n",
    "DE_txt = slicer_back(slicer_front(DE.get_text(),'IN the midway of this our'),'End of Project Gutenberg') # Delete the preface and conclusion\n",
    "DE_txt_c = re.sub('\\r\\n\\r\\n\\r\\n\\r\\n,+\\r\\n\\r\\n\\r\\n','\\r\\n',DE_txt) # Clean the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append sentances\n",
    "for line in DE_txt_c.split('\\r\\n'):\n",
    "    if line.strip():\n",
    "        corpus.append(line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43823"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read from website: http://www.gutenberg.org/cache/epub/21700/pg21700.txt\n",
    "\n",
    "Don Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJ = get_soup('http://www.gutenberg.org/cache/epub/21700/pg21700.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean preface, conclusion and titles\n",
    "DJ_txt = slicer_back(slicer_front(DJ.get_text(),'I want a hero: an uncommon want,'),'End of the Project Gutenberg EBook') # Delete the preface and conclusion\n",
    "DJ_txt_c = re.sub('\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n.+\\r\\n\\r\\n  ','\\r\\n',DJ_txt) # Clean the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59750"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append sentances\n",
    "for line in DJ_txt_c.split('\\r\\n'):\n",
    "    if line.strip():\n",
    "        corpus.append(line) \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from website: http://www.gutenberg.org/cache/epub/6524/pg6524.txt\n",
    "\n",
    "Stray Birds by Rabindranath Tagore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "StaryB = get_soup('http://www.gutenberg.org/cache/epub/6524/pg6524.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean preface, conclusion and titles\n",
    "StaryB_txt = slicer_back(slicer_front(StaryB.get_text(),'Stray birds of summer come to my window to sing and fly away.'),'End of the Project Gutenberg EBook') # Delete the preface and conclusion\n",
    "StaryB_txt_c1 = re.sub('\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n.+\\r\\n\\r\\n  ','\\r\\n',StaryB_txt) # Clean the titles\n",
    "StaryB_txt_c = re.sub('[1-9]\\d*','',StaryB_txt_c1) # Clean the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60372"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append sentances\n",
    "for line in StaryB_txt_c.split('\\r\\n'):\n",
    "    if line.strip():\n",
    "        corpus.append(line) \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from website: http://www.gutenberg.org/cache/epub/30488/pg30488.txt\n",
    "\n",
    "The Green Helmet and Other Poems by William Butler Yeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GH = get_soup('http://www.gutenberg.org/cache/epub/30488/pg30488.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean preface, conclusion and titles\n",
    "GH_txt = slicer_back(slicer_front(GH.get_text(),'I swayed upon the gaudy stern'),'THE GREEN HELMET') # Delete the preface and conclusion\n",
    "GH_txt_c = re.sub('\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n.+\\r\\n\\r\\n  ','\\r\\n',GH_txt) # Clean the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60718"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append sentances\n",
    "for line in GH_txt_c.split('\\r\\n'):\n",
    "    if line.strip():\n",
    "        corpus.append(line) \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from website: http://www.gutenberg.org/files/38520/38520-0.txt\n",
    "\n",
    "Poems of James Russell Lowell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "JRL = get_soup('http://www.gutenberg.org/files/38520/38520-0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean preface, conclusion and titles\n",
    "JRL_txt = slicer_back(slicer_front(JRL.get_text(),'If some small savor creep into my rhyme'),'MEMORIAL VERSES.') # Delete the preface and conclusion\n",
    "JRL_txt_c1 = re.sub('\\r\\n\\r\\n\\r\\n.+\\r\\n  ','\\r\\n',JRL_txt) # Clean the titles\n",
    "JRL_txt_c2 = re.sub('\\r\\n\\r\\n.+\\r\\n  ','\\r\\n',JRL_txt_c1) # Clean the titles\n",
    "JRL_txt_c3 = re.sub('\\r\\n.+\\r\\n\\r\\n  ','\\r\\n',JRL_txt_c2) # Clean the titles\n",
    "JRL_txt_c = re.sub('[1-9]\\d*\\.','',JRL_txt_c3) # Clean the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69734"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append sentances\n",
    "for line in JRL_txt_c.split('\\r\\n'):\n",
    "    if line.strip():\n",
    "        corpus.append(line) \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from website: http://www.gutenberg.org/cache/epub/19188/pg19188.txt\n",
    "\n",
    "Christina G. Rossetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CGR = get_soup('http://www.gutenberg.org/cache/epub/19188/pg19188.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean preface, conclusion and titles\n",
    "CGR_txt = slicer_back(slicer_front(CGR.get_text(),'Morning and evening'),'We trust to Thee.') # Delete the preface and conclusion\n",
    "CGR_txt_c1 = re.sub('\\r\\n\\r\\n\\r\\n.+\\r\\n  ','\\r\\n',CGR_txt) # Clean the titles\n",
    "CGR_txt_c2 = re.sub('\\r\\n\\r\\n.+\\r\\n  ','\\r\\n',CGR_txt_c1) # Clean the titles\n",
    "CGR_txt_c3 = re.sub('\\r\\n.+\\r\\n\\r\\n  ','\\r\\n',CGR_txt_c2) # Clean the titles\n",
    "CGR_txt_c = re.sub('[1-9]\\d*\\.','',CGR_txt_c3) # Clean the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78713"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append sentances\n",
    "for line in CGR_txt_c.split('\\r\\n'):\n",
    "    if line.strip():\n",
    "        corpus.append(line) \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('corpus_CGR.txt','w')  \n",
    "for line in corpus:\n",
    "    file.write(line+'\\n') \n",
    "file.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
